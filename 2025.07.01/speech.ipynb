{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b44c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7880\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7880/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "# STT(음성 → 텍스트) 요청 함수\n",
    "def request_stt(audio_path):\n",
    "    endpoint = f\"{os.getenv('AZURE_SPEECH_ENDPOINT_URL')}/speech/recognition/conversation/cognitiveservices/v1?language=ko-KR\"\n",
    "\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": \"45SFNywqabNccYBIp1fGDsJKJYe5N1pfPZLrSlLGY1ebDzyPLT75JQQJ99BFACYeBjFXJ3w3AAAYACOGWzIo\"\n",
    "    }\n",
    "\n",
    "    with open(audio_path, \"rb\") as audio_file:\n",
    "        audio_data = audio_file.read()\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, data=audio_data)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "\n",
    "    response_json = response.json()\n",
    "    content = response_json[\"DisplayText\"]\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "# TTS(텍스트 → 음성) 요청 함수\n",
    "def request_tts(text, voice=\"ko-KR-SunHiNeural\"):\n",
    "    endpont = f\"{os.getenv('AZURE_SPEECH_ENDPOINT_URL')}/cognitiveservices/v1\"\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": f\"{os.getenv('AZURE_SPEECH_API_KEY')}\",\n",
    "        \"X-Microsoft-OutputFormat\": \"riff-8khz-16bit-mono-pcm\",\n",
    "        \"Content-Type\": \"application/ssml+xml\",\n",
    "    }\n",
    "    # SSML 형식으로 요청 본문 생성\n",
    "    body = f\"\"\"\n",
    "        <speak version='1.0' xml:lang='ko-KR'>\n",
    "            <voice xml:lang='ko-KR' xml:gender='Female' name='{voice}'>\n",
    "                {text}\n",
    "            </voice>\n",
    "        </speak>\n",
    "    \"\"\"\n",
    "    response = requests.post(endpont, headers=headers, data=body)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "    import datetime\n",
    "\n",
    "    now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    filename = f\"tts_result_{now}.wav\"\n",
    "    with open(filename, \"wb\") as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "    return filename\n",
    "\n",
    "\n",
    "# GPT API 요청 함수\n",
    "def request_gpt(text):\n",
    "    endpoint = f\"{os.getenv('AZURE_OPENAI_ENDPOINT_URL')}/openai/deployments/fimtrus-gpt-41/chat/completions?api-version=2025-01-01-preview\"\n",
    "    headers = {\"Authorization\": f\"Bearer {os.getenv('AZURE_OPENAI_API_KEY')}\"}\n",
    "    body = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": text}],\n",
    "        \"max_completion_tokens\": 800,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"model\": \"fimtrus-gpt-41\",\n",
    "    }\n",
    "    response = requests.post(endpoint, headers=headers, json=body)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "    response_json = response.json()\n",
    "    content = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return content\n",
    "\n",
    "\n",
    "# Gradio UI 정의\n",
    "with gr.Blocks() as demo:\n",
    "    voice_list = [\n",
    "        \"ko-KR-SunHiNeural\",\n",
    "        \"ko-KR-InJoonNeural\",\n",
    "        \"ko-KR-HyunsuMultilingualNeural\",\n",
    "        \"ko-KR-BongJinNeural\",\n",
    "        \"ko-KR-GookMinNeural\",\n",
    "        \"ko-KR-HyunsuNeural\",\n",
    "        \"ko-KR-JiMinNeural\",\n",
    "        \"ko-KR-SeoHyeonNeural\",\n",
    "        \"ko-KR-SoonBokNeural\",\n",
    "        \"ko-KR-YuJinNeural\",\n",
    "    ]\n",
    "\n",
    "    # 오디오 입력이 변경될 때 STT 실행\n",
    "    def change_audio(audio_path):\n",
    "        if audio_path is None:\n",
    "            return None\n",
    "        content = request_stt(audio_path)\n",
    "        return content\n",
    "\n",
    "    # TTS 버튼 클릭 시 실행\n",
    "    def click_send_tts(text):\n",
    "        filename = request_tts(text)\n",
    "        return filename\n",
    "\n",
    "    # GPT 전송 버튼 클릭 시 실행\n",
    "    def send_gpt(text, histories):\n",
    "        content = request_gpt(text)\n",
    "        print(histories)\n",
    "        print(content)\n",
    "        # 대화 기록에 사용자/AI 메시지 추가\n",
    "        histories.append({\"role\": \"user\", \"content\": text})\n",
    "        histories.append({\"role\": \"assistant\", \"content\": content})\n",
    "        # 챗봇 이벤트로 이동해야함.\n",
    "        filename = request_tts(content)\n",
    "        return histories, filename\n",
    "\n",
    "    def change_prompt_audio(audio_path):\n",
    "        if audio_path is None:\n",
    "            return None\n",
    "\n",
    "        text = request_stt(audio_path)\n",
    "        return text\n",
    "\n",
    "    def change_prompt_text(text, histories):\n",
    "        if text is None or text == \"\":\n",
    "            return histories\n",
    "\n",
    "        content = request_gpt(text)\n",
    "\n",
    "        # 대화 기록에 사용자/AI 메시지 추가\n",
    "        histories.append({\"role\": \"user\", \"content\": text})\n",
    "        histories.append({\"role\": \"assistant\", \"content\": content})\n",
    "\n",
    "        return histories\n",
    "\n",
    "    def change_chatbot(histories, voice):\n",
    "        content = histories[-1][\"content\"]\n",
    "\n",
    "        pattern = r\"[^가-힣a-zA-Z0-9\\s!.,]\"\n",
    "\n",
    "        cleaned_content = re.sub(pattern, \"\", content)\n",
    "\n",
    "        filename = request_tts(cleaned_content, voice)\n",
    "\n",
    "        return filename\n",
    "\n",
    "    def change_voice(voice):\n",
    "        return voice\n",
    "\n",
    "    # UI 레이아웃 구성\n",
    "    with gr.Row():\n",
    "        # 좌측: 챗봇, 입력창, GPT 음성 출력\n",
    "        with gr.Column(scale=3):\n",
    "            chatbot = gr.Chatbot(type=\"messages\")\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    prompt_audio = gr.Audio(\n",
    "                        sources=\"microphone\", label=\"질문\", type=\"filepath\"\n",
    "                    )\n",
    "\n",
    "                with gr.Column(scale=3):\n",
    "                    prompt_textbox = gr.Textbox(\n",
    "                        label=\"메시지 입력\",\n",
    "                        placeholder=\"여기에 메시지를 입력하세요.\",\n",
    "                        interactive=False,\n",
    "                    )\n",
    "\n",
    "                # with gr.Column(scale=1):\n",
    "                #     send_gpt_button = gr.Button(\"전송\")\n",
    "\n",
    "            voice_dropdown = gr.Dropdown(\n",
    "                choices=voice_list,\n",
    "                label=\"음성 선택\",\n",
    "                value=\"ko-KR-SunHiNeural\",\n",
    "                type=\"value\",\n",
    "            )\n",
    "\n",
    "            gpt_audio = gr.Audio(\n",
    "                label=\"GPT 음성 출력\", type=\"filepath\", interactive=False, autoplay=True\n",
    "            )\n",
    "        # 우측: STT, TTS\n",
    "        with gr.Column(scale=1):\n",
    "            # STT 영역\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### STT\")\n",
    "                input_audio = gr.Audio(\n",
    "                    sources=\"microphone\", type=\"filepath\", label=\"마이크 입력\"\n",
    "                )\n",
    "                output_text = gr.Textbox(\n",
    "                    label=\"음성 인식 결과\",\n",
    "                    placeholder=\"여기에 음성 인식 결과가 표시됩니다.\",\n",
    "                    interactive=False,\n",
    "                )\n",
    "            # TTS 영역\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### TTS\")\n",
    "                tts_textbox = gr.Textbox(\n",
    "                    label=\"텍스트 입력\", placeholder=\"텍스트를 입력하세요.\"\n",
    "                )\n",
    "                send_tts_button = gr.Button(\"음성으로 변환\")\n",
    "                output_tts_audio = gr.Audio(\n",
    "                    label=\"음성 출력\", type=\"filepath\", interactive=False, autoplay=True\n",
    "                )\n",
    "\n",
    "    # 이벤트 연결\n",
    "    input_audio.change(change_audio, inputs=[input_audio], outputs=[output_text])\n",
    "    send_tts_button.click(\n",
    "        click_send_tts, inputs=[tts_textbox], outputs=[output_tts_audio]\n",
    "    )\n",
    "    # send_gpt_button.click(send_gpt, inputs=[prompt_textbox, chatbot], outputs=[chatbot, gpt_audio])\n",
    "\n",
    "    prompt_audio.input(\n",
    "        change_prompt_audio, inputs=[prompt_audio], outputs=[prompt_textbox]\n",
    "    )\n",
    "\n",
    "    prompt_textbox.change(\n",
    "        change_prompt_text, inputs=[prompt_textbox, chatbot], outputs=[chatbot]\n",
    "    )\n",
    "\n",
    "    chatbot.change(\n",
    "        change_chatbot, inputs=[chatbot, voice_dropdown], outputs=[gpt_audio]\n",
    "    )\n",
    "\n",
    "    voice_dropdown.change(\n",
    "        change_voice, inputs=[voice_dropdown], outputs=[voice_dropdown]\n",
    "    )\n",
    "\n",
    "# Gradio 앱 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1793d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
