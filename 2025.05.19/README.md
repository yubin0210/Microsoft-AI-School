# ğŸ’» 2025.05.19 - í•™ìŠµ ë…¸íŠ¸

---

## âœï¸ í•™ìŠµ ë‚´ìš©

í…ìŠ¤íŠ¸ ë§ˆì´ë‹, ë¹„ì§€ë„ í•™ìŠµ(êµ°ì§‘í™”), ê·¸ë¦¬ê³  ì›¹ í¬ë¡¤ë§ì— ëŒ€í•œ ì‹¤ìŠµì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. `KoNLPy`ë¥¼ í™œìš©í•˜ì—¬ í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³  ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ìµí˜”ìŠµë‹ˆë‹¤. K-Means êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ê·¸ë£¹í™”í•˜ê³ , ì—˜ë³´ìš° ë°©ë²•ê³¼ ì‹¤ë£¨ì—£ ë¶„ì„ì„ í†µí•´ ìµœì ì˜ êµ°ì§‘ ê°œìˆ˜ë¥¼ ì°¾ëŠ” ë°©ë²•ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, í”„ë¡œì•¼êµ¬ ì„ ìˆ˜ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ PCA(ì£¼ì„±ë¶„ ë¶„ì„) ì ìš© ì—¬ë¶€ì— ë”°ë¥¸ êµ°ì§‘í™” ê²°ê³¼ë¥¼ ë¹„êµ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ `requests`ì™€ `BeautifulSoup` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜ì§‘í•˜ëŠ” ì›¹ í¬ë¡¤ë§ ê¸°ìˆ ì„ ìŠµë“í–ˆìŠµë‹ˆë‹¤.

---

## ğŸ“ íŒŒì¼ ëª©ë¡

- `03_á„‹á…¯á„ƒá…³á„á…³á†¯á„…á…¡á„‹á…®á„ƒá…³á„‰á…µá„€á…¡á†¨á„’á…ª.ipynb`: `KoNLPy`ë¥¼ ì´ìš©í•œ í•œê¸€ í…ìŠ¤íŠ¸ ì›Œë“œí´ë¼ìš°ë“œ ì‹œê°í™” ì‹¤ìŠµ.
- `05_á„€á…®á†«á„Œá…µá†¸á„’á…ª_k-means*.ipynb`: `make_blobs`ë¡œ ìƒì„±ëœ ê°€ìƒ ë°ì´í„°ë¥¼ ì´ìš©í•œ K-Means êµ°ì§‘í™” ì‹¤ìŠµ.
- `06_á„€á…®á†«á„Œá…µá†¸á„’á…ª_á„‘á…³á„…á…©á„‹á…£á„€á…®*.ipynb`: í”„ë¡œì•¼êµ¬ ì„ ìˆ˜ ë°ì´í„°ë¥¼ í™œìš©í•œ K-Means êµ°ì§‘í™” ë° PCA ì ìš© ë¹„êµ ì‹¤ìŠµ.
- `silhouette_analysis.py`: ì‹¤ë£¨ì—£ ë¶„ì„ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸.
- `Crawling/`: ì›¹ í¬ë¡¤ë§ ì‹¤ìŠµ íŒŒì¼ë“¤ì´ í¬í•¨ëœ í´ë”ì…ë‹ˆë‹¤.
  - `01_á„Œá…¥á†¼á„Œá…¥á†¨á„‹á…°á†¸á„‘á…¦á„‹á…µá„Œá…µ á„ƒá…¦á„‹á…µá„á…¥ á„‰á…®á„Œá…µá†¸*.ipynb`: ì •ì  ì›¹í˜ì´ì§€ì—ì„œ ë°ì´í„° ìˆ˜ì§‘í•˜ëŠ” ê¸°ë³¸ ì‹¤ìŠµ.
  - `02_á„‚á…¦á„‹á…µá„‡á…¥á„‚á…²á„‰á…³á„ƒá…¦á„‹á…µá„á…¥á„‰á…®á„Œá…µá†¸*.ipynb`: ë„¤ì´ë²„ ì¦ê¶Œ ë‰´ìŠ¤ì—ì„œ ì—¬ëŸ¬ í˜ì´ì§€ì˜ ë‰´ìŠ¤ ë°ì´í„° ë° ë³¸ë¬¸ ë‚´ìš©ê¹Œì§€ ìˆ˜ì§‘í•˜ëŠ” ì‹¤ìŠµ.

---

## ğŸ“Œ ì£¼ìš” ì½”ë“œ

### 1. K-Means êµ°ì§‘í™” ë° ì‹¤ë£¨ì—£ ë¶„ì„
*ë°ì´í„°ë¥¼ K-Meansë¡œ êµ°ì§‘í™”í•˜ê³ , ì‹¤ë£¨ì—£ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ êµ°ì§‘ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.*
```python
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import silhouette_analysis as s

k = 3 # ìµœì ì˜ k ê°’
km = KMeans(n_clusters=k, random_state=10)
cluster_labels = km.fit_predict(scaled_features) # scaled_featuresëŠ” ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°

print(f'ì‹¤ë£¨ì—£ ì ìˆ˜: {silhouette_score(scaled_features, cluster_labels):.2f}')
s.silhouette_plot(scaled_features, k) # ì‹¤ë£¨ì—£ í”Œë¡¯ ì‹œê°í™”
```

### 2. ì›¹ í¬ë¡¤ë§ (requests, BeautifulSoup)
*`requests`ë¡œ ì›¹ í˜ì´ì§€ë¥¼ ìš”ì²­í•˜ê³ , `BeautifulSoup`ìœ¼ë¡œ HTMLì„ íŒŒì‹±í•˜ì—¬ ì›í•˜ëŠ” ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.*
```python
import requests
from bs4 import BeautifulSoup

url = 'https://finance.naver.com/news/mainnews.naver'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# ë‰´ìŠ¤ ì œëª© ì¶”ì¶œ
article_titles = [a.text for a in soup.select(".articleSubject > a")]

# ë‰´ìŠ¤ ë§í¬ ì¶”ì¶œ
article_links = [a.attrs['href'] for a in soup.select(".articleSubject > a")]

print(article_titles[0])
print(article_links[0])
```

### 3. PCA (ì£¼ì„±ë¶„ ë¶„ì„)
*ë°ì´í„°ì˜ ì°¨ì›ì„ ì¶•ì†Œí•˜ê³ , ì£¼ì„±ë¶„ìœ¼ë¡œ ë³€í™˜ëœ ë°ì´í„°ë¥¼ í™œìš©í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.*
```python
from sklearn.decomposition import PCA

pca = PCA(n_components=2) # 2ê°œì˜ ì£¼ì„±ë¶„ìœ¼ë¡œ ì¶•ì†Œ
principal_components = pca.fit_transform(X_scaled) # X_scaledëŠ” ìŠ¤ì¼€ì¼ë§ëœ ì›ë³¸ ë°ì´í„°

# ì„¤ëª…ëœ ë¶„ì‚° ë¹„ìœ¨ í™•ì¸
print(pca.explained_variance_ratio_)

# ëˆ„ì  ë¶„ì‚° í™•ì¸
print(pca.explained_variance_ratio_.cumsum())
```

---

## About Me

**Yubin Kim (ê¹€ìœ ë¹ˆ)**

[![Blog](https://img.shields.io/badge/Blog-FF5722?style=for-the-badge&logo=blogger&logoColor=white)](https://cases.tistory.com/)
<a href="https://github.com/yubi0210"><img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white" alt="GitHub"/></a>

## ğŸ“ Contact
[![Gmail](https://img.shields.io/badge/ubinn0210@gmail.com-D14836?style=for-the-badge&logo=gmail&logoColor=white)](ubinn0210@gmail.com)


---
