# ðŸ’» 2025.06.30 - í•™ìŠµ ë…¸íŠ¸

---

## âœï¸ í•™ìŠµ ë‚´ìš©

`Gradio`ë¥¼ í™œìš©í•˜ì—¬ `Azure OpenAI` ì„œë¹„ìŠ¤ì˜ ì±—ë´‡ ê¸°ëŠ¥ì„ í†µí•©í•œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì‚¬ìš©ìžì˜ í…ìŠ¤íŠ¸ ìž…ë ¥ì„ ë°›ì•„ `Azure OpenAI` ì±— ëª¨ë¸ì´ ì‘ë‹µì„ ìƒì„±í•˜ê³ , ì´ ì‘ë‹µì„ `Azure Speech Service`ë¥¼ í†µí•´ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©ìžì—ê²Œ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ë§ˆì´í¬ë¥¼ í†µí•œ ìŒì„± ìž…ë ¥(`STT`)ê³¼ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜(`TTS`)í•˜ëŠ” ê¸°ëŠ¥ë„ í¬í•¨ë˜ì–´ ìžˆì–´, ìŒì„± ê¸°ë°˜ì˜ ëŒ€í™”í˜• AI ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.

---

## ðŸ“ íŒŒì¼ ëª©ë¡

- `main.py`: `Gradio` ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ì¸ íŒŒì¼ë¡œ, ì±—ë´‡, ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜(STT), í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜(TTS) ê¸°ëŠ¥ì„ í†µí•©í•œ ì‚¬ìš©ìž ì¸í„°íŽ˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- `services/openai_service.py`: `Azure OpenAI` APIì™€ì˜ ìƒí˜¸ìž‘ìš©ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤ ë¡œì§ì„ í¬í•¨í•©ë‹ˆë‹¤. ì±—ë´‡ ì‘ë‹µì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ì´ í¬í•¨ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.
- `data/`: ë°ì´í„° íŒŒì¼ë“¤ì´ í¬í•¨ëœ í´ë”.
- `results/`: ê²°ê³¼ íŒŒì¼ë“¤ì´ ì €ìž¥ë˜ëŠ” í´ë”.

---

## ðŸ“Œ ì£¼ìš” ì½”ë“œ

### 1. `Gradio`ë¥¼ ì´ìš©í•œ ì±—ë´‡ ë° ìŒì„± ê¸°ëŠ¥ í†µí•© ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
*`Gradio`ì˜ `gr.Blocks()`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì±—ë´‡, STT, TTS ê¸°ëŠ¥ì„ í†µí•©í•œ ì‚¬ìš©ìž ì¸í„°íŽ˜ì´ìŠ¤ë¥¼ ì •ì˜í•˜ëŠ” ì½”ë“œìž…ë‹ˆë‹¤.*
```python
import gradio as gr
import sys
import os

# í•„ìš”í•œ ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
directories_to_add = ["2025.06.24", "2025.06.27"]
for directory in directories_to_add:
    path_to_add = os.path.abspath(os.path.join(current_dir, "..", directory))
    if path_to_add not in sys.path: sys.path.append(path_to_add)

from speech import transcribe_audio, synthesize_speech, get_voice_list
from services.openai_service import OpenAIService

if __name__ == "__main__":
    with gr.Blocks() as demo:
        openai_service = OpenAIService()
        with gr.Row():
            with gr.Column():
                chatbot = gr.Chatbot(type="messages")
                user_input = gr.Textbox(label="Message", placeholder="Enter your message here...")
                send_button = gr.Button("Send")

                send_button.click(
                    fn=openai_service.chat,
                    inputs=[user_input, chatbot],
                    outputs=[user_input, chatbot, gr.Audio(visible=True)], # output_audioë¥¼ visibleí•˜ê²Œ ì„¤ì •
                )
                user_input.submit(
                    fn=openai_service.chat,
                    inputs=[user_input, chatbot],
                    outputs=[user_input, chatbot, gr.Audio(visible=True)],
                )

            with gr.Column():
                gr.Markdown("# Speech to Text")
                input_audio = gr.Audio(label="ìŒì„± ìž…ë ¥", type="filepath", sources=["microphone"])
                output_text = gr.Textbox(label="ìŒì„± ì¸ì‹ ê²°ê³¼", interactive=False)
                input_audio.change(
                    lambda audio_path: (
                        transcribe_audio(audio_path, language="ko-KR").get("DisplayText")
                        if audio_path is not None
                        else ""
                    ),
                    inputs=[input_audio],
                    outputs=[output_text],
                )

                gr.Markdown("# Text to Speech")
                input_text = gr.Textbox(label="í…ìŠ¤íŠ¸ ìž…ë ¥", placeholder="í…ìŠ¤íŠ¸ë¥¼ ìž…ë ¥í•˜ê³  ìŒì„±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
                voice_list = gr.Dropdown(label="ìŒì„± ì„ íƒ", choices=get_voice_list())
                submit_button = gr.Button("ìŒì„± ìƒì„±")
                output_audio = gr.Audio(label="ìŒì„± ì¶œë ¥", type="filepath", interactive=False, autoplay=True)
                submit_button.click(
                    lambda text, voice: synthesize_speech(text, voice),
                    inputs=[input_text, voice_list],
                    outputs=[output_audio],
                )

    demo.launch()
```

### 2. `OpenAIService`ì˜ ì±— ê¸°ëŠ¥ (`services/openai_service.py`)
*`Azure OpenAI` ì±— ëª¨ë¸ê³¼ ìƒí˜¸ìž‘ìš©í•˜ë©°, ì±—ë´‡ ì‘ë‹µì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•˜ëŠ” ì½”ë“œìž…ë‹ˆë‹¤.*
```python
import os
import sys
from typing import Any, Dict, List, Optional
from openai import AzureOpenAI
from dotenv import load_dotenv

load_dotenv()

# speech ëª¨ë“ˆ ìž„í¬íŠ¸ (ê²½ë¡œ ì„¤ì • í•„ìš”)
current_dir = os.path.dirname(os.path.abspath(__file__))
directories_to_add = ["2025.06.27"]
for directory in directories_to_add:
    path_to_add = os.path.abspath(os.path.join(current_dir, "..", directory))
    if path_to_add not in sys.path: sys.path.append(path_to_add)
from speech import synthesize_speech

class OpenAIService:
    def __init__(self) -> None:
        self.chat_client = AzureOpenAI(
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            api_version="2024-12-01-preview",
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT_URL"),
        )
        self.chat_system_prompt: Dict[str, Any] = {
            "role": "system",
            "content": "ì‚¬ìš©ìžê°€ ì •ë³´ë¥¼ ì°¾ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” AI professional assistantìž…ë‹ˆë‹¤.",
        }

    def chat(
        self,
        prompt: str,
        history: List[List[str]],
        args: Optional[Dict[str, Any]] = None,
    ) -> tuple[str, list[list[str]]]:
        if not prompt: return "", history, None
        messages: List[Dict[str, Any]] = [self.chat_system_prompt]
        messages.extend(history)
        messages.append({"role": "user", "content": prompt})

        response_message = self._request_to_openai(messages, args)
        messages.append({"role": "assistant", "content": response_message.content})

        return "", messages, synthesize_speech(response_message.content, "ko-KR-YuJinNeural")

    def _request_to_openai(
        self,
        messages: List[Dict[str, Any]],
        args: Optional[Dict[str, Any]] = None,
    ) -> Any:
        response = self.chat_client.chat.completions.create(
            model=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
            messages=messages,
            max_tokens=args.get("max_tokens", 16384),
            temperature=args.get("temperature", 0.7),
            top_p=args.get("top_p", 0.95),
            frequency_penalty=args.get("frequency_penalty", 0),
            presence_penalty=args.get("presence_penalty", 0),
            stop=args.get("stop", None),
            stream=args.get("stream", False),
            extra_body=args.get("extra_body", {}),
        )
        return response.choices[0].message
```

---

## About Me

**Yubin Kim (ê¹€ìœ ë¹ˆ)**

[![Blog](https://img.shields.io/badge/Blog-FF5722?style=for-the-badge&logo=blogger&logoColor=white)](https://cases.tistory.com/)
<a href="https://github.com/yubi0210"><img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white" alt="GitHub"/></a>

## ðŸ“ž Contact
[![Gmail](https://img.shields.io/badge/ubinn0210@gmail.com-D14836?style=for-the-badge&logo=gmail&logoColor=white)](ubinn0210@gmail.com)


---
